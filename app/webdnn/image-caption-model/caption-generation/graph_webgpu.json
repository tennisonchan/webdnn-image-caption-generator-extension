{
  "converted_at": 1520475802,
  "kernel_source": "\n#include <metal_stdlib>\nusing namespace metal;\n\n#define OPTIMIZE 1\n\nkernel void embedding_5681741bb5b48844184ce968ca45a9acbe6bfb0e8ea9da87a38098a2(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint global_index[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n    const device float *X = (static_buffer + meta_buffer[0]);\n    device float       *Y = (static_buffer + meta_buffer[1]);\n    const device float *W = (static_buffer + meta_buffer[2]);\n\n    const int T = meta_buffer[3];\n    const int N = meta_buffer[4];\n    const int C = meta_buffer[5];\n\n    for (int gid = global_index; gid < N * T; gid += num_threads) {\n        const int t = gid % T;\n        const int n = gid / T;\n\n        const int word = (int)X[gid];\n        for (int c = 0; c < C; c++) {\n            Y[(n * T + t) * C + c] = W[word * C + c];\n        }\n    }\n}\n\n\nkernel void fusedelementwise_8e9d606b17a50c4bcd26495c38d60d95077f4a2c4c89461b008dfbff(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint gid[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n    const device float * v1 = (static_buffer + meta_buffer[0]);\n    const device float * v2 = (static_buffer + meta_buffer[1]);\n    const device float * v3 = (static_buffer + meta_buffer[2]);\n    const device float * v4 = (static_buffer + meta_buffer[3]);\n    device float * v5 = (static_buffer + meta_buffer[4]);\n    const int D0 = meta_buffer[5];\n    int d0;\n    for (d0 = gid; d0 < D0; d0 += num_threads) {\n        const float v6 = v1[d0];\n        const float v7 = v3[d0];\n        float v8;\n        {\n            v8 = v6 * v7;\n        }\n        const float v9 = v2[d0];\n        const float v10 = v4[d0];\n        float v11;\n        {\n            v11 = v9 * v10;\n        }\n        float v12;\n        {\n            v12 = v11 + v8;\n        }\n        v5[d0] = v12;\n    }\n}\n\n\nkernel void lstm_22bf557d912dc882a179f628ee2189854cff077c666d942d8299f4f2(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer[[buffer(2)]],\n                          uint global_index[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n#define USE_INITIAL_C 1\n#define USE_INITIAL_H 1\n#define activation_function(x) (metal::precise::tanh(x))\n#define recurrent_activation_function(x) (metal::precise::tanh(0.5f * (x)) * 0.5f + 0.5f)\n#define RETURN_SEQUENCES 0\n\n    const device float  *X         = (static_buffer + meta_buffer[0]);\n          device float  *XH        = (static_buffer + meta_buffer[7]);\n    const device float  *W_all     = (static_buffer + meta_buffer[8]);\n          device float  *workspace = (static_buffer + meta_buffer[9]);\n          device float  *Y         = (static_buffer + meta_buffer[1]);\n          device float  *final_C   = (static_buffer + meta_buffer[10]);\n    const device float  *b         = (static_buffer + meta_buffer[2]);\n\n#if USE_INITIAL_C\n    const device float  *initial_C = (static_buffer + meta_buffer[11]);\n#endif\n#if USE_INITIAL_H\n    const device float  *initial_H = (static_buffer + meta_buffer[12]);\n#endif\n\n    const int N  = meta_buffer[3];\n    const int T  = meta_buffer[4];\n    const int C1 = meta_buffer[5];\n    const int C2 = meta_buffer[6];\n\n    device float *XH_X = XH;\n    device float *XH_H = XH + C1 * N;\n\n    //reset output and cell state\n    for (int gid = global_index; gid < N * C2; gid += num_threads)\n    {\n#if USE_INITIAL_H\n        XH_H[gid] = initial_H[gid];\n#else\n        XH_H[gid] = 0;\n#endif\n\n#if USE_INITIAL_C\n        final_C[gid] = initial_C[gid];\n#else\n        final_C[gid] = 0;\n#endif\n    }\n\n    for (int t = 0; t < T; t++)\n    {\n        for (int gid = global_index; gid < C1 * N; gid += num_threads)\n        {\n            const int n = gid % N;\n            const int c1 = gid / N;\n            XH_X[gid] = X[(n * T + t) * C1 + c1];\n        }\n\n        threadgroup_barrier(mem_flags::mem_device);\n\n        //FIXME: replace here to more efficient sgemv implementation.\n        // `4` means the number of hidden matrices (input, forget, activation, output).\n        for (int gid = global_index; gid < C2 * 4 * N; gid += num_threads)\n        {\n            const int n = gid % N;\n            const int c2_4 = gid / N;\n\n            float v = b[c2_4];\n\n            for (int c1c2 = 0; c1c2 < C1 + C2; c1c2++)\n            {\n                v += XH[c1c2 * N + n] * W_all[c1c2 * C2 * 4 + c2_4];\n            }\n\n            workspace[gid] = v;\n        }\n\n        threadgroup_barrier(mem_flags::mem_device);\n\n        for (int gid = global_index; gid < C2 * N; gid += num_threads)\n        {\n            const int n = gid % N;\n            const int c2 = gid / N;\n\n            float i = workspace[gid + N * C2 * 0];\n            float f = workspace[gid + N * C2 * 1];\n            float a = workspace[gid + N * C2 * 2];\n            float o = workspace[gid + N * C2 * 3];\n            float c = final_C[n * C2 + c2];\n\n            i = recurrent_activation_function(i);\n            f = recurrent_activation_function(f);\n            a = activation_function(a);\n            o = recurrent_activation_function(o);\n\n            c = a * i + c * f;\n\n            final_C[n * C2 + c2] = c;\n            const float h = activation_function(c) * o;\n            XH_H[gid] = h;\n\n#if RETURN_SEQUENCES\n            Y[(n * T + t) * C2 + c2] = h;\n#endif\n        }\n    }\n\n#if !RETURN_SEQUENCES\n    //copy final output to output variable\n    for (int gid = global_index; gid < C2 * N; gid += num_threads)\n    {\n        const int n = gid % N;\n        const int c2 = gid / N;\n        Y[n * C2 + c2] = XH_H[gid];\n    }\n#endif\n\n#undef USE_INITIAL_C\n#undef USE_INITIAL_H\n#undef activation_function\n#undef recurrent_activation_function\n#undef RETURN_SEQUENCES\n}\n    \n\nkernel void transpose_004b4f39e9e976c3a0c2492294b329e4263fa637435784552851f71d(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint gid[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n    const device float * v1 = (static_buffer + meta_buffer[0]);\n    device float * v2 = (static_buffer + meta_buffer[1]);\n    const int D0 = meta_buffer[2];\n    int d0;\n    for (d0 = gid; d0 < D0; d0 += num_threads) {\n        const float v3 = v1[d0];\n        float v4;\n        {\n            v4 = v3;\n        }\n        v2[d0] = v4;\n    }\n}\n\n\nkernel void tensordot_92d010c077e5e47e7d25245f52cbec2d36848fa15bbaf804a3bb662a(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint index[[thread_index_in_threadgroup]],\n                          uint2 group_position[[threadgroup_position_in_grid]])\n{\n#define M_DIVIDABLE_BY_64 0\n#define N_DIVIDABLE_BY_64 0\n#define K_DIVIDABLE_BY_8 1\n\n#define A_STRIDE_K M\n#define A_STRIDE_M 1\n\n#define B_STRIDE_K N\n#define B_STRIDE_N 1\n\n#if K_DIVIDABLE_BY_8 && M_DIVIDABLE_BY_64 && N_DIVIDABLE_BY_64 && OPTIMIZE\n    const device float4 *load_target4 = (index & 32)\n        ? (const device float4 *)((static_buffer + meta_buffer[1]))\n        : (const device float4 *)((static_buffer + meta_buffer[0]));\n#else\n    const device float *load_target = (index & 32)\n        ? ((static_buffer + meta_buffer[1]))\n        : ((static_buffer + meta_buffer[0]));\n#endif\n\n    const int M = meta_buffer[3];\n    const int N = meta_buffer[4];\n\n    const int K = meta_buffer[5];\n\n    threadgroup float4 shared4[32 * 8 * 2];\n\n    const int stride_k = (index & 32) ? B_STRIDE_K : A_STRIDE_K;\n    const int stride_mn = (index & 32) ? B_STRIDE_N : A_STRIDE_M;\n\n    const int m_offset = index & 7;\n    const int n_offset = index >> 3;\n\n    const int mn_load_offset = ((index & 32) ? group_position.y : group_position.x) * 64 + (index & 15) * 4;\n    const int k_load_offset = ((index & 16) ? 1 : 0);\n\n    int track0 = mn_load_offset * stride_mn + (k_load_offset + 0) * stride_k;\n    int track2 = track0 + 2 * stride_k;\n    int track4 = track0 + 4 * stride_k;\n    int track6 = track0 + 6 * stride_k;\n\n#if !OPTIMIZE || !M_DIVIDABLE_BY_64 || !N_DIVIDABLE_BY_64\n    const int max_MN = (index & 32) ? N : M;\n#endif\n\n    int shared_offset4 = ((index & 32) ? 16 : 0) + k_load_offset * 32 + (index & 15);\n    int read_A_offset4 = m_offset * 2;\n    int read_B_offset4 = n_offset * 2 + 16;\n\n    float4 result[16] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};\n    int k = 0;\n\n    while (k < K)\n    {\n        {\n#if OPTIMIZE && K_DIVIDABLE_BY_8\n    #if OPTIMIZE && M_DIVIDABLE_BY_64 && N_DIVIDABLE_BY_64\n        #if OPTIMIZE\n            shared4[shared_offset4 + 32 * 0] = load_target4[track0 >> 2];\n            shared4[shared_offset4 + 32 * 2] = load_target4[track2 >> 2];\n            shared4[shared_offset4 + 32 * 4] = load_target4[track4 >> 2];\n            shared4[shared_offset4 + 32 * 6] = load_target4[track6 >> 2];\n        #else\n            shared4[shared_offset4 + 32 * 0] = float4(\n                load_target[track0 + stride_mn * 0],\n                load_target[track0 + stride_mn * 1],\n                load_target[track0 + stride_mn * 2],\n                load_target[track0 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 2] = float4(\n                load_target[track2 + stride_mn * 0],\n                load_target[track2 + stride_mn * 1],\n                load_target[track2 + stride_mn * 2],\n                load_target[track2 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 4] = float4(\n                load_target[track4 + stride_mn * 0],\n                load_target[track4 + stride_mn * 1],\n                load_target[track4 + stride_mn * 2],\n                load_target[track4 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 6] = float4(\n                load_target[track6 + stride_mn * 0],\n                load_target[track6 + stride_mn * 1],\n                load_target[track6 + stride_mn * 2],\n                load_target[track6 + stride_mn * 3]\n            );\n        #endif\n    #else\n            shared4[shared_offset4 + 32 * 0] = float4(\n                (mn_load_offset + 0 >= max_MN) ? 0 : load_target[track0 + stride_mn * 0],\n                (mn_load_offset + 1 >= max_MN) ? 0 : load_target[track0 + stride_mn * 1],\n                (mn_load_offset + 2 >= max_MN) ? 0 : load_target[track0 + stride_mn * 2],\n                (mn_load_offset + 3 >= max_MN) ? 0 : load_target[track0 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 2] = float4(\n                (mn_load_offset + 0 >= max_MN) ? 0 : load_target[track2 + stride_mn * 0],\n                (mn_load_offset + 1 >= max_MN) ? 0 : load_target[track2 + stride_mn * 1],\n                (mn_load_offset + 2 >= max_MN) ? 0 : load_target[track2 + stride_mn * 2],\n                (mn_load_offset + 3 >= max_MN) ? 0 : load_target[track2 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 4] = float4(\n                (mn_load_offset + 0 >= max_MN) ? 0 : load_target[track4 + stride_mn * 0],\n                (mn_load_offset + 1 >= max_MN) ? 0 : load_target[track4 + stride_mn * 1],\n                (mn_load_offset + 2 >= max_MN) ? 0 : load_target[track4 + stride_mn * 2],\n                (mn_load_offset + 3 >= max_MN) ? 0 : load_target[track4 + stride_mn * 3]\n            );\n            shared4[shared_offset4 + 32 * 6] = float4(\n                (mn_load_offset + 0 >= max_MN) ? 0 : load_target[track6 + stride_mn * 0],\n                (mn_load_offset + 1 >= max_MN) ? 0 : load_target[track6 + stride_mn * 1],\n                (mn_load_offset + 2 >= max_MN) ? 0 : load_target[track6 + stride_mn * 2],\n                (mn_load_offset + 3 >= max_MN) ? 0 : load_target[track6 + stride_mn * 3]\n            );\n    #endif\n\n            k += 8;\n#else\n    #if OPTIMIZE && M_DIVIDABLE_BY_64 && N_DIVIDABLE_BY_64\n            shared4[shared_offset4 + 32 * 0] = float4(\n                (k + k_load_offset >= K) ? 0 : load_target[track0 + stride_mn * 0],\n                (k + k_load_offset >= K) ? 0 : load_target[track0 + stride_mn * 1],\n                (k + k_load_offset >= K) ? 0 : load_target[track0 + stride_mn * 2],\n                (k + k_load_offset >= K) ? 0 : load_target[track0 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 2] = float4(\n                (k + k_load_offset >= K) ? 0 : load_target[track2 + stride_mn * 0],\n                (k + k_load_offset >= K) ? 0 : load_target[track2 + stride_mn * 1],\n                (k + k_load_offset >= K) ? 0 : load_target[track2 + stride_mn * 2],\n                (k + k_load_offset >= K) ? 0 : load_target[track2 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 4] = float4(\n                (k + k_load_offset >= K) ? 0 : load_target[track4 + stride_mn * 0],\n                (k + k_load_offset >= K) ? 0 : load_target[track4 + stride_mn * 1],\n                (k + k_load_offset >= K) ? 0 : load_target[track4 + stride_mn * 2],\n                (k + k_load_offset >= K) ? 0 : load_target[track4 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 6] = float4(\n                (k + k_load_offset >= K) ? 0 : load_target[track6 + stride_mn * 0],\n                (k + k_load_offset >= K) ? 0 : load_target[track6 + stride_mn * 1],\n                (k + k_load_offset >= K) ? 0 : load_target[track6 + stride_mn * 2],\n                (k + k_load_offset >= K) ? 0 : load_target[track6 + stride_mn * 3]\n            );\n            k += 2;\n    #else\n            shared4[shared_offset4 + 32 * 0] = float4(\n                (k + k_load_offset >= K || mn_load_offset + 0 >= max_MN) ? 0 : load_target[track0 + stride_mn * 0],\n                (k + k_load_offset >= K || mn_load_offset + 1 >= max_MN) ? 0 : load_target[track0 + stride_mn * 1],\n                (k + k_load_offset >= K || mn_load_offset + 2 >= max_MN) ? 0 : load_target[track0 + stride_mn * 2],\n                (k + k_load_offset >= K || mn_load_offset + 3 >= max_MN) ? 0 : load_target[track0 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 2] = float4(\n                (k + k_load_offset >= K || mn_load_offset + 0 >= max_MN) ? 0 : load_target[track2 + stride_mn * 0],\n                (k + k_load_offset >= K || mn_load_offset + 1 >= max_MN) ? 0 : load_target[track2 + stride_mn * 1],\n                (k + k_load_offset >= K || mn_load_offset + 2 >= max_MN) ? 0 : load_target[track2 + stride_mn * 2],\n                (k + k_load_offset >= K || mn_load_offset + 3 >= max_MN) ? 0 : load_target[track2 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 4] = float4(\n                (k + k_load_offset >= K || mn_load_offset + 0 >= max_MN) ? 0 : load_target[track4 + stride_mn * 0],\n                (k + k_load_offset >= K || mn_load_offset + 1 >= max_MN) ? 0 : load_target[track4 + stride_mn * 1],\n                (k + k_load_offset >= K || mn_load_offset + 2 >= max_MN) ? 0 : load_target[track4 + stride_mn * 2],\n                (k + k_load_offset >= K || mn_load_offset + 3 >= max_MN) ? 0 : load_target[track4 + stride_mn * 3]\n            );\n            k += 2;\n\n            shared4[shared_offset4 + 32 * 6] = float4(\n                (k + k_load_offset >= K || mn_load_offset + 0 >= max_MN) ? 0 : load_target[track6 + stride_mn * 0],\n                (k + k_load_offset >= K || mn_load_offset + 1 >= max_MN) ? 0 : load_target[track6 + stride_mn * 1],\n                (k + k_load_offset >= K || mn_load_offset + 2 >= max_MN) ? 0 : load_target[track6 + stride_mn * 2],\n                (k + k_load_offset >= K || mn_load_offset + 3 >= max_MN) ? 0 : load_target[track6 + stride_mn * 3]\n            );\n            k += 2;\n    #endif\n#endif\n        }\n\n        threadgroup_barrier(mem_flags::mem_threadgroup);\n\n        {\n            for (int k_sub = 0; k_sub < 8; k_sub++)\n            {\n                float4 a00 = shared4[32 * k_sub + read_A_offset4 + 0];\n                float4 a01 = shared4[32 * k_sub + read_A_offset4 + 1];\n                float4 b00 = shared4[32 * k_sub + read_B_offset4 + 0];\n                float4 b01 = shared4[32 * k_sub + read_B_offset4 + 1];\n\n                result[4][0]  += b00[0] * a00[2];\n                result[4][1]  += b00[1] * a00[2];\n                result[0][1]  += b00[1] * a00[0];\n                result[0][0]  += b00[0] * a00[0];\n                result[6][0]  += b00[0] * a00[3];\n                result[6][1]  += b00[1] * a00[3];\n                result[2][1]  += b00[1] * a00[1];\n                result[2][0]  += b00[0] * a00[1];\n                result[12][0] += b00[0] * a01[2];\n                result[12][1] += b00[1] * a01[2];\n                result[8][1]  += b00[1] * a01[0];\n                result[8][0]  += b00[0] * a01[0];\n                result[14][0] += b00[0] * a01[3];\n                result[14][1] += b00[1] * a01[3];\n                result[10][1] += b00[1] * a01[1];\n                result[10][0] += b00[0] * a01[1];\n\n                result[14][2] += b00[2] * a01[3];\n                result[14][3] += b00[3] * a01[3];\n                result[10][3] += b00[3] * a01[1];\n                result[10][2] += b00[2] * a01[1];\n                result[12][2] += b00[2] * a01[2];\n                result[12][3] += b00[3] * a01[2];\n                result[8][3]  += b00[3] * a01[0];\n                result[8][2]  += b00[2] * a01[0];\n                result[6][2]  += b00[2] * a00[3];\n                result[6][3]  += b00[3] * a00[3];\n                result[2][3]  += b00[3] * a00[1];\n                result[2][2]  += b00[2] * a00[1];\n                result[4][2]  += b00[2] * a00[2];\n                result[4][3]  += b00[3] * a00[2];\n                result[0][3]  += b00[3] * a00[0];\n                result[0][2]  += b00[2] * a00[0];\n\n                result[5][0]  += b01[0] * a00[2];\n                result[5][1]  += b01[1] * a00[2];\n                result[1][1]  += b01[1] * a00[0];\n                result[1][0]  += b01[0] * a00[0];\n                result[7][0]  += b01[0] * a00[3];\n                result[7][1]  += b01[1] * a00[3];\n                result[3][1]  += b01[1] * a00[1];\n                result[3][0]  += b01[0] * a00[1];\n                result[13][0] += b01[0] * a01[2];\n                result[13][1] += b01[1] * a01[2];\n                result[9][1]  += b01[1] * a01[0];\n                result[9][0]  += b01[0] * a01[0];\n                result[15][0] += b01[0] * a01[3];\n                result[15][1] += b01[1] * a01[3];\n                result[11][1] += b01[1] * a01[1];\n                result[11][0] += b01[0] * a01[1];\n\n                result[15][2] += b01[2] * a01[3];\n                result[15][3] += b01[3] * a01[3];\n                result[11][3] += b01[3] * a01[1];\n                result[11][2] += b01[2] * a01[1];\n                result[13][2] += b01[2] * a01[2];\n                result[13][3] += b01[3] * a01[2];\n                result[9][3]  += b01[3] * a01[0];\n                result[9][2]  += b01[2] * a01[0];\n                result[7][2]  += b01[2] * a00[3];\n                result[7][3]  += b01[3] * a00[3];\n                result[3][3]  += b01[3] * a00[1];\n                result[3][2]  += b01[2] * a00[1];\n                result[5][2]  += b01[2] * a00[2];\n                result[5][3]  += b01[3] * a00[2];\n                result[1][3]  += b01[3] * a00[0];\n                result[1][2]  += b01[2] * a00[0];\n            }\n        }\n\n        shared_offset4 ^= 32 * 8;\n        read_A_offset4 ^= 32 * 8;\n        read_B_offset4 ^= 32 * 8;\n        track0 += stride_k * 8;\n        track2 += stride_k * 8;\n        track4 += stride_k * 8;\n        track6 += stride_k * 8;\n    }\n\n    {\n\n#if OPTIMIZE && N_DIVIDABLE_BY_64\n        device float4 *C4 = (device float4 *)((static_buffer + meta_buffer[2]));\n        const int N4 = N >> 2;\n        int m = group_position.x * 64 + m_offset * 8;\n        for (int m_sub = 0; m_sub < 8; m_sub++)\n        {\n\n    #if !M_DIVIDABLE_BY_64\n            if (m >= M) continue;\n    #endif\n\n            const int n = group_position.y * 16 + n_offset * 2;\n            float4 result0 = result[m_sub * 2 + 0];\n            float4 result1 = result[m_sub * 2 + 1];\n\n            C4[m * N4 + n + 0] = result0;\n            C4[m * N4 + n + 1] = result1;\n\n            m++;\n        }\n#else\n        device float *C = (static_buffer + meta_buffer[2]);\n        int m = group_position.x * 64 + m_offset * 8;\n        for (int m_sub = 0; m_sub < 8; m_sub++)\n        {\n            int n = group_position.y * 64 + n_offset * 8;\n\n            for (int n_sub1 = 0; n_sub1 < 2; n_sub1++)\n            {\n                for (int n_sub2 = 0; n_sub2 < 4; n_sub2++)\n                {\n\n    #if OPTIMIZE && M_DIVIDABLE_BY_64\n                    (         n < N) ? (C[m * N + n] = result[m_sub * 2 + n_sub1][n_sub2]) : 0;\n    #else\n                    (m < M && n < N) ? (C[m * N + n] = result[m_sub * 2 + n_sub1][n_sub2]) : 0;\n    #endif\n                    n++;\n                }\n            }\n\n            m++;\n        }\n#endif\n\n    }\n\n#undef M_DIVIDABLE_BY_64\n#undef N_DIVIDABLE_BY_64\n#undef K_DIVIDABLE_BY_8\n#undef A_STRIDE_K\n#undef B_STRIDE_K\n#undef A_STRIDE_M\n#undef B_STRIDE_N\n}\n\n\nkernel void elementwiseadd_59df3b0d6feefd576062ac58c68e6dade28056ea47dd0a57294bdf90(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint gid[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n    const device float * v1 = (static_buffer + meta_buffer[0]);\n    const device float * v2 = (static_buffer + meta_buffer[1]);\n    device float * v3 = (static_buffer + meta_buffer[2]);\n    const int D0 = meta_buffer[3];\n    int d0;\n    for (d0 = gid; d0 < D0; d0 += num_threads) {\n        const float v4 = v1[d0];\n        const float v5 = v2[d0];\n        float v6;\n        {\n            v6 = v5 + v4;\n        }\n        v3[d0] = v6;\n    }\n}\n\n\nkernel void softmax_c5c1093e2f2f79baae8036b89eb70752cc1a574cf4c28310442568eb(device float * static_buffer[[buffer(0)]],\n                          device float * dynamic_buffer[[buffer(1)]],\n                          const device int * meta_buffer [[buffer(2)]],\n                          uint index[[thread_position_in_grid]],\n                          uint num_threads[[threads_per_grid]])\n{\n    const device float *X = (static_buffer + meta_buffer[0]);\n    device float *Y = (static_buffer + meta_buffer[1]);\n    const int D1 = meta_buffer[2];\n    const int D2 = meta_buffer[3];\n    const int D3 = meta_buffer[4];\n\n    for (int gid = index; gid < D1 * D3; gid += num_threads) {\n        const int d3 = gid % D3;\n        const int d1 = gid / D3;\n\n        float set_max = 0.0f;\n        for (int d2 = 0; d2 < D2; d2++) {\n            float val = X[(d1 * D2 + d2) * D3 + d3];\n            if (val > set_max) {\n                set_max = val;\n            }\n        }\n\n        float sum_exp = 0.0f;\n        for (int d2 = 0; d2 < D2; d2++) {\n            float val = X[(d1 * D2 + d2) * D3 + d3];\n            float exp_x = exp(val - set_max);\n            sum_exp += exp_x;\n            Y[(d1 * D2 + d2) * D3 + d3] = exp_x;\n        }\n\n        for (int d2 = 0; d2 < D2; d2++) {\n            Y[(d1 * D2 + d2) * D3 + d3] /= sum_exp;\n        }\n    }\n}\n",
  "exec_infos": [
    {
      "entry_func_name": "embedding_5681741bb5b48844184ce968ca45a9acbe6bfb0e8ea9da87a38098a2",
      "threadgroups_per_grid": {
        "width": 8,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        178,
        204,
        169,
        0,
        178,
        192,
        169,
        0,
        0,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        2,
        0,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "fusedelementwise_8e9d606b17a50c4bcd26495c38d60d95077f4a2c4c89461b008dfbff",
      "threadgroups_per_grid": {
        "width": 8,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        178,
        198,
        169,
        0,
        178,
        192,
        169,
        0,
        178,
        200,
        169,
        0,
        178,
        202,
        169,
        0,
        178,
        198,
        169,
        0,
        0,
        2,
        0,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "lstm_22bf557d912dc882a179f628ee2189854cff077c666d942d8299f4f2",
      "threadgroups_per_grid": {
        "width": 1,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        178,
        198,
        169,
        0,
        178,
        196,
        169,
        0,
        0,
        178,
        68,
        0,
        1,
        0,
        0,
        0,
        1,
        0,
        0,
        0,
        0,
        2,
        0,
        0,
        0,
        2,
        0,
        0,
        178,
        184,
        169,
        0,
        0,
        186,
        68,
        0,
        178,
        176,
        169,
        0,
        178,
        188,
        169,
        0,
        178,
        194,
        169,
        0,
        178,
        190,
        169,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "transpose_004b4f39e9e976c3a0c2492294b329e4263fa637435784552851f71d",
      "threadgroups_per_grid": {
        "width": 8,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        178,
        196,
        169,
        0,
        178,
        176,
        169,
        0,
        0,
        2,
        0,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "tensordot_92d010c077e5e47e7d25245f52cbec2d36848fa15bbaf804a3bb662a",
      "threadgroups_per_grid": {
        "width": 1,
        "height": 138,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": 64,
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        178,
        176,
        169,
        0,
        0,
        186,
        100,
        0,
        89,
        142,
        169,
        0,
        1,
        0,
        0,
        0,
        89,
        34,
        0,
        0,
        0,
        2,
        0,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "elementwiseadd_59df3b0d6feefd576062ac58c68e6dade28056ea47dd0a57294bdf90",
      "threadgroups_per_grid": {
        "width": 8,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        0,
        108,
        169,
        0,
        89,
        142,
        169,
        0,
        89,
        142,
        169,
        0,
        89,
        34,
        0,
        0
      ],
      "unresolved_value_list": []
    },
    {
      "entry_func_name": "softmax_c5c1093e2f2f79baae8036b89eb70752cc1a574cf4c28310442568eb",
      "threadgroups_per_grid": {
        "width": 8,
        "height": 1,
        "depth": 1
      },
      "threads_per_thread_group": {
        "width": {
          "eval": "placeholders['__MAX_THREADS_PER_THREADGROUP__'];"
        },
        "height": 1,
        "depth": 1
      },
      "meta_buffer": [
        89,
        142,
        169,
        0,
        89,
        142,
        169,
        0,
        1,
        0,
        0,
        0,
        89,
        34,
        0,
        0,
        1,
        0,
        0,
        0
      ],
      "unresolved_value_list": []
    }
  ],
  "weight_encoding": "eightbit",
  "memory_layout": {
    "static": {
      "size": 11127987,
      "allocations": {
        "a280": {
          "name": "a280",
          "offset": 11126450,
          "size": 512
        },
        "a265": {
          "name": "a265",
          "offset": 11127986,
          "size": 1
        },
        "a266": {
          "name": "a266",
          "offset": 11126962,
          "size": 512
        },
        "a267": {
          "name": "a267",
          "offset": 11127474,
          "size": 512
        },
        "a268": {
          "name": "a268",
          "offset": 11124402,
          "size": 512
        },
        "a269": {
          "name": "a269",
          "offset": 11125426,
          "size": 512
        },
        "a273": {
          "name": "a273",
          "offset": 11124914,
          "size": 512
        },
        "a276": {
          "name": "a276",
          "offset": 11120818,
          "size": 2048
        },
        "a275": {
          "name": "a275",
          "offset": 11122866,
          "size": 1024
        },
        "a271": {
          "name": "a271",
          "offset": 11125938,
          "size": 512
        },
        "a277": {
          "name": "a277",
          "offset": 11120818,
          "size": 512
        },
        "a282": {
          "name": "a282",
          "offset": 11112025,
          "size": 8793
        },
        "a272": {
          "name": "a272",
          "offset": 11123890,
          "size": 512
        },
        "a259": {
          "name": "a259",
          "offset": 0,
          "size": 4502016
        },
        "a260": {
          "name": "a260",
          "offset": 4502016,
          "size": 2048
        },
        "a261": {
          "name": "a261",
          "offset": 4504064,
          "size": 2097152
        },
        "a262": {
          "name": "a262",
          "offset": 6601216,
          "size": 4502016
        },
        "a263": {
          "name": "a263",
          "offset": 11103232,
          "size": 8793
        }
      }
    },
    "dynamic": {
      "size": 0,
      "allocations": {}
    }
  },
  "placeholders": {
    "__MAX_THREADS_PER_THREADGROUP__": null
  },
  "inputs": [
    "a280",
    "a265",
    "a266",
    "a267",
    "a268",
    "a269"
  ],
  "outputs": [
    "a282",
    "a271",
    "a272"
  ],
  "licenses": {
    "webdnn": "(C) Machine Intelligence Laboratory (The University of Tokyo), MIT License"
  }
}